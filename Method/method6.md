# 《Lexical Diversity-aware Relevance Assessment for Retrieval-Augmented Generation》
论文针对传统检索增强生成（RAG）忽略查询词汇多样性、导致检索语义匹配偏差与生成噪声干扰的问题，提出**词汇多样性感知RAG（DRAG）** 框架。该方法通过“多样性敏感相关性分析器（DRA）”实现细粒度检索匹配，结合“风险引导稀疏校准（RSC）”抑制生成噪声，形成“检索-生成”双阶段优化闭环。以下详细拆解方法原理、数学表达、代码实现与实验验证，所有内容均源自目标论文。

-Zhang Z, Ma Y, Wang Y, et al. Lexical Diversity-aware Relevance Assessment for Retrieval-Augmented Generation[C]//Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2025: 27758-27781.

## 一、核心概念与方法框架
DRAG的核心是通过**词汇多样性建模**打破传统RAG“单标准检索+全token生成”的局限，框架包含两大核心模块，关键概念与流程定义如下（论文3.1-3.3节）：

### 1. 核心概念
- **词汇多样性（Lexical Diversity）**：查询中不同组件的表达差异，论文将查询组件划分为三类，是DRA的设计基础：
  - <Invariant>（不变组件）：无表达差异的实体类信息（如“Portland”“Hattie McDaniel”），需检索文档**显式提及**才能匹配；
  - <Variant>（可变组件）：多表达的概念类信息（如“occupation”可表述为“profession”“actress”“career”），需文档**语义关联**即可匹配；
  - <Supplementary>（补充组件）：查询未显式提及但可推理的辅助信息（如“State or country”对应“Portland的首都归属”），需文档**间接支撑**以辅助匹配。
- **多样性敏感相关性分析器（DRA）**：将查询按词汇多样性分解为三类组件，针对不同组件采用差异化相关性评估标准，筛选语义精准的检索文档，解决“词汇相似但语义无关”的检索偏差；
- **无关风险（Irrelevance Risk）**：检索文档中无关噪声对生成token的干扰程度，论文定义三类风险维度（词汇风险、注意力风险、预测风险），量化不同token的噪声敏感度；
- **风险引导稀疏校准（RSC）**：仅对高无关风险的token进行解码校准，通过“噪声参考文档”修正生成分布，避免全token校准的高计算开销，同时保留低风险token的语义完整性。

### 2. 方法框架流程
DRAG的完整流程分为**检索阶段**与**生成阶段**，逻辑如下（论文3.1节、附录B Algorithm 1）：
1. **检索阶段（DRA主导）**：
   -$$ 输入查询\(x\)与初始检索文档集合\(D\)（由Contriever-MS MARCO检索器获取）$$；
   - 分解查询为<Invariant>/<Variant>/<Supplementary>组件；
   - $$按组件类型计算每个文档的相关性得分，筛选top-r相关文档\(D_{rel}\)，并确定噪声参考文档\(T^{ref}\)（得分最低的文档）$$；
2. **生成阶段（RSC主导）**：
   - $$基于\(D_{rel}\)生成初始文本，实时量化每个token的无关风险$$；
   - $$对高风险token（风险值≥阈值\(\delta\)），对比\(T^{ref}\)的生成分布进行校准$$；
   - 输出校准后的最终文本，实现“精准检索+高效降噪”。


## 二、数学公式与符号定义
论文通过严格数学定义规范DRAG的核心计算逻辑，以下为关键公式与符号说明（论文3.2-3.3节）：

### 1. 符号约定
| 符号          | 含义说明                                  | 示例                          |
|---------------|-------------------------------------------|-------------------------------|
| \$$(x\$$)         | 输入查询                                  | “What is Hattie McDaniel’s occupation?” |
| \$$(D = \{d_1,...,d_k\}$$\) | 初始检索文档集合                  | 5-10篇Wikipedia相关文档        |
| \$$(C = \{<c_j,a_j>\}$$\) | 查询分解后的组件集合（\($$a_j$$\)为组件属性） | \(Hattie McDaniel, Invariant) |
| \$$(S_i\$$)       | 文档\($$d_i$$\)的总相关性得分                | 0.8（高相关）、0.2（低相关）   |
| \$$(r_t^{lex}/r_t^{attn}/r_t^{pred}$$\) | 第\(t\)个token的词汇/注意力/预测风险 | 0.4/0.3/0.5                   |
| \($$r_t\$$)       | 第\(t\)个token的总无关风险                | \(0.4 \times 0.3 \times 0.5 = 0.06\) |
| \($$T^{ref}$$\)   | 噪声参考文档（相关性最低的文档）          | 含“Hattie McDaniel”但无关“occupation”的文档 |

### 2. DRA：查询分解与相关性评分
#### （1）查询组件分解
$$DRA模块\(\mathcal{F}\)基于指令\(I_{dec}\)（“从问题中提取关键组件并分类”），将查询\(x\)分解为带属性的组件集合$$，数学表达为：
$$C = \mathcal{F}(I_{dec}, x; \theta_{\mathcal{F}})$$
- $$\(\theta_{\mathcal{F}}\)：DRA的训练参数（基于Qwen-0.5B微调，论文4.1节）$$；
- $$\(I_{dec}\)：固定指令，确保分解逻辑一致性（如“<Invariant>为实体，<Variant>为多表达概念，<Supplementary>为推理辅助信息”）$$。

#### （2）组件级相关性得分
针对不同属性的组件，采用差异化评分标准（论文3.2节）：
- 对<Invariant>组件（\(a_j=\text{Invariant}\)）：二进制评分\(\sigma_1\)，文档显式提及则\(s_{i,j}=1\)，否则为0；
- 对<Variant>/<Supplementary>组件（\(a_j=\text{Variant}/\text{Supplementary}\)）：连续评分\(\sigma_2\)，\(s_{i,j} \in [0,1]\)（得分越高语义关联越强）。

#### （3）文档总相关性得分
通过加权和聚合组件得分，得到文档\(d_i\)的总相关性（权重由论文4.3节消融实验确定）：
$$S_i = 1.0 \times s_{i,\text{inv}} + \alpha \times s_{i,\text{var}} + \beta \times s_{i,\text{sup}}$$
- $$\(s_{i,\text{inv}}/s_{i,\text{var}}/s_{i,\text{sup}}\)：文档\(d_i\)对三类组件的得分$$；
- $$\(\alpha=0.8\)（<Variant>组件权重）、\(\beta=0.5\)（<Supplementary>组件权重）：平衡可变概念的语义重要性与补充信息的辅助性$$。

### 3. RSC：无关风险量化与稀疏校准
#### （1）三类风险计算
论文定义三类风险维度，全面量化噪声对token的干扰（论文3.3节）：
- **词汇风险**：组件多样性越高，信息提取难度越大，风险越高：
$$r_t^{lex} = \lambda_1 \cdot N_{\text{inv}} + \lambda_2 \cdot N_{\text{var}} + \lambda_3 \cdot N_{\text{sup}}$$
  - $$\(N_{\text{inv}}/N_{\text{var}}/N_{\text{sup}}\)：三类组件的数量$$；
  - $$\(\lambda_1=0.1, \lambda_2=0.4, \lambda_3=0.5\)（论文附录C验证，反映多样性对风险的贡献度）$$。

- **注意力风险**：token对低相关性文档的注意力权重越高，风险越高：
$$r_t^{attn} = \sum_{i=1}^k \frac{A_{i,t}}{1 + S_i}$$
  - $$\(A_{i,t}\)：第\(t\)个token对文档\(d_i\)的总注意力权重$$；
  - $$\(S_i\)：文档\(d_i\)的相关性得分（得分越低，分母越小，风险越高）$$。

- **预测风险**：token生成概率越低，不确定性越高，风险越高：
$$r_t^{pred} = 1 - p_t$$
  - $$\(p_t\)：模型对第\(t\)个token的最大预测概率（如生成“actress”的概率为0.7，则\(r_t^{pred}=0.3\)）$$。

#### （2）总风险与稀疏校准
- **总无关风险**：三类风险的乘积（需同时满足“多样性高+注意力偏误+预测不确定”才判定为高风险）：
$$r_t = r_t^{lex} \cdot r_t^{attn} \cdot r_t^{pred}$$

- **稀疏校准逻辑**：仅当\(r_t \geq \delta\)（\(\delta=0.3\)，论文4.3节最优阈值）时，通过\(T^{ref}\)修正解码分布，公式为：
$$y_t = \begin{cases} 
\mathcal{M}(x, y_{<t}, D_{rel}; \theta_{\mathcal{M}}) - \gamma \cdot \mathcal{M}(x, y_{<t}, T^{ref}; \theta_{\mathcal{M}}) & r_t \geq \delta \\
\mathcal{M}(x, y_{<t}, D_{rel}; \theta_{\mathcal{M}}) & r_t < \delta 
\end{cases}$$
  - \(\mathcal{M}\)：生成模型（Llama3-8B-Instruct，论文4.1节）；
  - \(\gamma=0.6\)：校准权重（平衡噪声抑制与语义保留）；
  - \(y_{<t}\)：第\(t\)个token之前的生成序列。



## 三、实现关键要点（基于论文实验结论）
论文通过大量消融实验与分析，明确DRAG的关键实现细节与参数选择，以下为核心要点（论文4.3-4.4节）：

### 1. DRA组件权重（α、β）的优化
- **<Variant>组件权重α**：呈**倒U型分布**（图3(a)），α=0.8时性能最优——α过低（如0.4）会忽略可变概念的语义关联（如“Academy Award”与“occupation”的间接关联）；α过高（如1.2）会引入冗余匹配（如“career”匹配无关职业文档）；
- **<Supplementary>组件权重β**：β=0.5为宜——补充信息仅辅助匹配，权重过高（如0.8）易导致“过度检索”（如“American celebrity”匹配无关名人文档），权重过低（如0.2）则无法发挥辅助作用。

### 2. RSC风险阈值δ与校准效率
- **阈值δ=0.3**：平衡校准精度与计算开销（图3(b)）：
  - δ<0.3：校准低风险token（如“the”“is”等连接词），增加40%计算开销但无性能提升；
  - δ>0.3：遗漏高风险token（如实体类token“actress”），导致噪声残留；
- **校准效率**：仅15%的token需校准（论文4.4节），生成阶段单迭代时间（10.38s/iter）比全token校准（20.93s/iter）低40%，比对比方法CAD（19.53s/iter）低47%（表4）。

### 3. 噪声参考文档T_ref的选择逻辑
T_ref必须满足“词汇相似但语义无关”（论文3.3节），而非随机无关文档：
- 错误选择：随机无关文档（如“Paris is the capital of France”）——与查询词汇无重叠，无法模拟真实检索噪声；
- 正确选择：DRA评分最低的文档（如含“Portland”但无关“首都”的“Portland气候”文档）——能精准模拟“词汇匹配但语义偏差”的真实噪声，校准效果提升12%（论文附录C）。

### 4. DRA的训练与泛化性
- **训练数据**：仅需6,743条数据（1,200条查询分解+5,543条相关性评分，表10），远少于Self-RAG的145,619条，训练成本低；
- **泛化性**：跨任务有效——在短文本生成（PopQA）、多跳推理（HotpotQA）、长文本生成（ASQA）任务中，平均准确率提升5.5~18.6%（表1），因词汇多样性是RAG的通用挑战，而非任务特定问题。


## 四、论文实验验证与结果
论文通过三类任务、多组基线对比与消融实验，验证DRAG的有效性，以下为关键实验信息（论文4.1-4.4节）：

### 1. 实验设置
- **数据集**：覆盖三类典型RAG任务（表1）：
  - 短文本生成：PopQA（事实准确性）、TriviaQA（事实准确性）；
  - 多跳推理：HotpotQA（准确率）、2WikiMultiHopQA（准确率）；
  - 长文本生成：ASQA（str-em、Rouge-L、QA-F1）；
- **基线对比**：
  - 无检索基线：ChatGPT、Llama2-7B-Chat、Llama3-8B-Instruct；
  - 有检索基线：Self-RAG、FLARE、QD-RAG、REPLUG、RECOMP；
- **评估指标**：短文本/多跳任务用**准确率（Acc）**，长文本任务用str-em（语义对齐）、QA-F1（问答匹配）。

### 2. 核心实验结果
#### （1）主任务性能（表1）
DRAG在所有任务中显著优于基线，尤其在多跳任务中提升明显：
| 任务                | 次优基线（Acc/关键指标） | DRAG（Acc/关键指标） | 提升幅度 |
|---------------------|--------------------------|----------------------|----------|
| PopQA（短文本）     | RECOMP（62.8%）          | 68.3%                | +5.5%    |
| HotpotQA（多跳）    | Self-RAG（28.2%）        | 46.4%                | +18.2%   |
| 2WikiMultiHopQA（多跳） | Self-RAG（36.0%）    | 54.6%                | +18.6%   |
| ASQA（长文本，QA-F1）| Llama3-8B-Instruct（22.9%） | 26.9%          | +4.0%    |

**关键原因**：DRA解决了多跳查询的词汇多样性匹配问题（如“Who is the mother of the director of Polish-Russian War?”需关联“Xawery Żuławski”与“Małgorzata Braunek”），RSC抑制了多文档的噪声累积。

#### （2）消融实验（表3）
验证DRA与RSC的协同作用，缺一不可：
| 模块组合       | HotpotQA准确率 | 性能变化       |
|----------------|----------------|----------------|
| 仅基线（Llama3-RAG） | 35.8%        | -              |
| 基线+仅DRA     | 38.9%          | +3.1%（检索优化） |
| 基线+仅RSC     | 38.2%          | +2.4%（生成优化） |
| 基线+DRA+RSC（DRAG） | 46.4%      | +10.6%（双阶段叠加） |

#### （3）计算效率对比（表4）
DRAG在性能与效率间实现平衡：
| 方法                | 单迭代时间（s/iter） | 准确率（PopQA） | 校准token比例 |
|---------------------|----------------------|-----------------|--------------|
| Llama3-8B（无检索） | 6.02                 | 63.4%           | -            |
| CAD（全token校准）  | 19.53                | 67.3%           | 100%         |
| DRAG（稀疏校准）    | 10.38                | 68.3%           | 15%          |


## 六、与传统RAG方法的核心差异
论文通过对比传统RAG方法（如Self-RAG、REPLUG），明确DRAG的创新点，差异如下（论文2.2节、4.4节）：

| 对比维度               | 传统RAG方法（如Self-RAG）               | DRAG（本文方法）                          |
|------------------------|-----------------------------------------|-------------------------------------------|
| 词汇多样性处理         | 忽略，用整句查询匹配文档（单标准评分）   | 分解为三类组件，差异化评估相关性（多标准） |
| 生成校准策略           | 全token校准（高开销）或不校准（高噪声）  | 仅校准高风险token（15%比例，低开销）      |
| 检索-生成协同性        | 检索与生成独立（嵌入空间不一致）         | 共享词汇多样性建模，嵌入与生成空间统一    |
| 跨任务泛化性           | 弱（依赖任务特定模板，如多跳分解模板）   | 强（词汇多样性是通用挑战，跨任务有效）    |
| 训练数据需求           | 高（如Self-RAG需14.5万条数据）          | 低（仅6,743条数据）                       |
| HotpotQA准确率         | 28.2%（Self-RAG）                       | 46.4%（提升18.2个百分点）                 |


## 七、总结
DRAG作为词汇多样性感知的RAG框架，通过“DRA细粒度检索+RSC稀疏校准”，解决了传统RAG的两大核心痛点：
1. **检索层面**：通过组件级差异化评分，避免“词汇相似但语义无关”的检索偏差，在多跳任务中检索准确率提升20%+；
2. **生成层面**：通过风险量化实现稀疏校准，在保证生成质量的同时降低40%计算开销。

实验表明，DRAG在8个知识密集型任务中平均提升5.5~18.6%关键指标，尤其在多跳推理与长文本生成中表现突出，为通用RAG系统的性能优化提供了“词汇多样性建模”的新范式，且训练成本低、泛化性强，具备实际应用价值（论文5-6节）。
